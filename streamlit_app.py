from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import ChatMessage
from langchain_openai import ChatOpenAI
import streamlit as st

import os
import nest_asyncio
from langchain.smith import RunEvalConfig, run_on_dataset

import requests
from urllib.parse import urlencode

nest_asyncio.apply()

os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
os.environ["LANGCHAIN_API_KEY"] = st.secrets["LANGCHAIN_API_KEY"]
os.environ["LANGCHAIN_TRACING_V2"] = st.secrets["LANGCHAIN_TRACING_V2"]
os.environ["LANGCHAIN_ENDPOINT"] = st.secrets["LANGCHAIN_ENDPOINT"]
os.environ["LANGCHAIN_PROJECT"] = st.secrets["LANGCHAIN_PROJECT"]

class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)

def get_db_data(user_question):
    base_url = "http://datalab.dscloud.me:9000/edufine"
    params = {
        'user_question': user_question
    }
      
    encoded_params = urlencode(params)
    url = f"{base_url}?{encoded_params}"
    response = requests.get(url)
      
    return response.text


#with st.sidebar:

st.set_page_config(
    page_title="K-ì—ë“€íŒŒì¸ ì—…ë¬´ê´€ë¦¬ AIì±—ë´‡",
    layout="wide"
)


st.subheader(":robot_face: :blue[ì—…ë¬´ê´€ë¦¬ AIì±—ë´‡](íŒŒì¼ëŸ¿)")

#if "messages" not in st.session_state:
with st.chat_message("system", avatar="ğŸ˜„"):
    st.write("ì•ˆë…•í•˜ì„¸ìš”! ğŸ‘‹ ì•„ë˜ ìƒ˜í”Œ ì§ˆë¬¸ì„ ì°¸ê³ í•´ì„œ ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì§ˆë¬¸í•˜ì„¸ìš”.")

#with st.chat_message("system", avatar="â—"):
#    st.write("ì´ ì±—ë´‡ì€ 'ì‹¤í—˜ë²„ì „'ì…ë‹ˆë‹¤.")

with st.chat_message("user"):
    st.write("ìˆ˜ì‹ ë¬¸ì„œë¥¼ ë°°ë¶€í•˜ë ¤ëŠ”ë° ì–´ë””ë¡œ ë³´ë‚´ì•¼ ë ì§€ ëª¨ë¥´ê² ëŠ”ë°?")

with st.chat_message("assistant"):
    st.write("ìˆ˜ì‹ ë¬¸ì„œë¥¼ ë°°ë¶€í•  ë•Œ ë‹´ë‹¹ ë¶€ì„œê°€ ë¶ˆëª…í™•í•œ ê²½ìš°, 'ë‹´ë‹¹ë¶€ì„œí™•ì¸' ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ë¶€ì„œë¡œ í™•ì¸ ìš”ì²­ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

with st.chat_message("user"):
    st.write("ì¤‘ë‹¨í•œ ë¬¸ì„œë„ ê¸°ë¡ë¬¼ ì´ê´€ ëŒ€ìƒì¸ê°€ìš”?")

with st.chat_message("assistant"):
    st.write("ë„¤, ì¤‘ë‹¨í•œ ë¬¸ì„œë„ ê¸°ë¡ë¬¼ ì´ê´€ ëŒ€ìƒì…ë‹ˆë‹¤. ë¬¸ì„œ ì¤‘ë‹¨ ì²˜ë¦¬ëŠ” ë¬¸ì„œë²ˆí˜¸ê°€ ë“±ë¡ë˜ì§€ ì•Šì§€ë§Œ, ì™„ë£Œë¬¸ì„œì™€ ë™ì¼í•˜ê²Œ ì·¨ê¸‰í•˜ì—¬ ê¸°ë¡ë¬¼ì´ê´€ ëŒ€ìƒì´ ë©ë‹ˆë‹¤.")


#ì²« ì‹¤í–‰ì¼ ë•Œ
if "messages" not in st.session_state:
    st.session_state.messages = []


for message in st.session_state.messages:
    if message["role"] in ["user", "assistant"]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])


if prompt := st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    #ì±—ë´‡ ì§€ì‹œì‚¬í•­
    st.session_state.messages.append({"role": "system", "content": """
    # ì´ ì±—ë´‡(ChatBot)ì— ëŒ€í•˜ì—¬
    
    ## ì—­í• 
    ë„ˆëŠ” í•œêµ­êµìœ¡í•™ìˆ ì •ë³´ì›(KERIS)ì˜ 'K-ì—ë“€íŒŒì¸ ì—…ë¬´ê´€ë¦¬ ì‹œìŠ¤í…œ' ì±—ë´‡ì´ë‹¤. 
    
    ## 'ì—…ë¬´ê´€ë¦¬ êµìœ¡ìë£Œ'ì— ëŒ€í•˜ì—¬
    - ë„ˆëŠ” '2024ë…„ ê¸°ì¤€ìœ¼ë¡œ ì—…ë°ì´íŠ¸ëœ 'ì—…ë¬´ê´€ë¦¬ êµìœ¡ìë£Œ'(ë”°ë¼í•˜ê¸° ë©”ë‰´ì–¼, êµìœ¡ë™ì˜ìƒ ëŒ€ë³¸)'ë¥¼ ì‹œìš©ì(ì§ˆë¬¸ì)ì˜ ì§ˆë¬¸ì— ë”°ë¼ RAG(Retrieval-Augmented Generation)ë°©ì‹ìœ¼ë¡œ ì¡°íšŒí•˜ì—¬ ì œê³µë°›ëŠ”ë‹¤.
    - ë„ˆì—ê²Œë§Œ 'ì—…ë¬´ê´€ë¦¬ êµìœ¡ìë£Œ'ë¥¼ ì œê³µí•˜ê³  ì‹œìš©ì(ì§ˆë¬¸ì)ëŠ” ë³¼ ìˆ˜ ì—†ë‹¤. ë”°ë¼ì„œ ì‹œìš©ì(ì§ˆë¬¸ì)ì—ê²Œ 'ì—…ë¬´ê´€ë¦¬ êµìœ¡ìë£Œ'ë¥¼ ì–¸ê¸‰í•˜ì§€ ì•ŠëŠ”ë‹¤.
    
    ## 'ì—…ë¬´ê´€ë¦¬ êµìœ¡ìë£Œ'ì˜ í˜•ì‹
    - 'ì—…ë¬´ê´€ë¦¬ êµìœ¡ìë£Œ'ì˜ ê°ê°ì€ 'ì¶œì²˜', 'ì¶œì²˜ ë‚´ ìœ„ì¹˜', 'ë‚´ìš©'ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.
    - '\n' ë¬¸ìëŠ” ê°œí–‰(ë‹¤ìŒì¤„ë¡œ ì´ë™)ì„ ì˜ë¯¸í•œë‹¤.
    - ì¶œì²˜ì— 'ë”°ë¼í•˜ê¸°'ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©ìë©”ë‰´ì–¼ ìë£Œê³ , 'ìœ íŠœë¸Œ'ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ êµìœ¡ìš©ë™ì˜ìƒ ìë£Œì´ë‹¤. 'ì‚¬ìš©ìì§€ì›ì„œë¹„ìŠ¤' ë° 'ì—ë“€ì½œì„¼í„°'ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì „êµ­ êµìœ¡ì²­ ë° í•™êµ ì‚¬ìš©ìë“¤ì´ ì§ˆë¬¸ì„ ë‚¨ê¸´ ê²ƒì— ëŒ€í•œ ë‹µë³€ì„ ë‚¨ê¸´ ìë£Œì´ë‹¤.
    
    ## ë‹µë³€ì˜ í˜•ì‹
    - ë„ˆì˜ ë‹µë³€ì€ ì½ê¸°ì‰¬ìš´ í˜•ì‹(ì˜ˆ : markdown)ìœ¼ë¡œ ì‘ì„±í•œë‹¤. ì‹œìš©ì(ì§ˆë¬¸ì)ë“¤ì€ 'K-ì—ë“€íŒŒì¸ì˜ ì—…ë¬´ê´€ë¦¬ ì‹œìŠ¤í…œ' ì‚¬ìš©ë²•ì— ëŒ€í•´ì„œ ì§ˆë¬¸í•œë‹¤.
    - ì‹œìŠ¤í…œ ì‚¬ìš©ë²• ë¬¸ì˜ì™€ ê´€ë ¨ì—†ëŠ” ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë‹µë³€í•˜ì§€ ì•ŠëŠ”ë‹¤. ì •í™•í•œ ë‹µë³€ë§Œ ì‘ì„±í•˜ê³  'ì—…ë¬´ê´€ë¦¬ êµìœ¡ìë£Œ'ì— ë‚´ìš©ì´ ì—†ëŠ” ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ì•Œì§€ ëª»í•œë‹¤ê³  ë‹µí•œë‹¤.
    - ë„ˆëŠ” ì‹œìš©ì(ì§ˆë¬¸ì)ê°€ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë‚˜ ê°œì„ ì‚¬í•­ì— ëŒ€í•œ ì§ˆë¬¸ì„ í•  ê²½ìš° ì‚¬ìš©ìì§€ì›ì„œë¹„ìŠ¤(help.klef.go.kr)ì— ì ‘ì†í•˜ì—¬ ê¸€ì„ ë‚¨ê¸°ë©´ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆë‹¤ê³  ë‹µë³€í•œë‹¤.
    
    ## í˜„ì¬ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë¦¬í¬íŠ¸ ìë£Œ
    - 
    """})
    
    st.session_state.messages.append({"role": "system", "content": """
    ## ì—…ë¬´ê´€ë¦¬ êµìœ¡ìë£Œ : 
    """ + get_db_data(prompt)})
    
    st.chat_message("user").write(prompt)

    with st.chat_message("assistant"):
        stream_handler = StreamHandler(st.empty())
        llm = ChatOpenAI(openai_api_key=os.environ["OPENAI_API_KEY"], model="gpt-4.1-mini", temperature=0.0, streaming=True, callbacks=[stream_handler])
        response = llm.invoke(st.session_state.messages)
        st.session_state.messages.append({"role": "assistant", "content": response.content})

        if st.session_state:
            if "messages" in st.session_state:
                if st.session_state.messages:
                    st.session_state.messages = [msg for msg in st.session_state.messages if msg.get("role") != "system"]
            
